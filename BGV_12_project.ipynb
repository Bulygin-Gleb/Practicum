{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7181465b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Глеб! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30379e7",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b66d8f",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561587f",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a330db0a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Вступление в работу очень важно, так человек, который смотрит твой проект (и на работе в том числе) будет сразу введен в курс дела. \n",
    "     \n",
    "    \n",
    " \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "   \n",
    "Вопросик, при желании можешь ответить )\n",
    "    \n",
    "    \n",
    "- а почему по твоему была выбрана метрика f1? \n",
    "    \n",
    "    \n",
    "- а что если бы нам было нужно найти как можно больше токсичных комментариев, в этом случаи на какую метрику мы бы ориентировались?\n",
    "    \n",
    "    \n",
    "- каким образом мы можем изменить функцию ошибки в модели, чтобы она максимизировала интересующую нас метрику (accuracy, f1, precision, roc-auc итп)?    \n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8caedb",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7bf769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8421db",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "- Собираем все импорты в верхней части, чтобы легче было ориентироваться и добавлять новые по необходимости. \n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет:     \n",
    "\n",
    "\n",
    "\n",
    "- кстати есть рекомендации PEP-8 при написании кода, в том числе и для импортов. Если интересно можешь почитать [тут](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html), это на будущее\n",
    "\n",
    "\n",
    "<div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becda307",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_toxic_comments=pd.read_csv( 'C:/Users/elve/Desktop/Обучение/data/toxic_comments.csv', sep=',')\n",
    "except:\n",
    "    data_toxic_comments=pd.read_csv('/datasets/toxic_comments.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c4af7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Молодец что используешь конструкцию try - except (if - else), этим ты проявляешь уважение к тем кто будет работать с твоим кодом.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0f152c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_toxic_comments['toxic'].value_counts()/data_toxic_comments.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc9e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data (data_i):\n",
    "    temp = data_i.copy() \n",
    "    # проверяем дубликаты\n",
    "    print('Кол-во дубликатов:',temp.duplicated().sum())\n",
    "    list_c=data_i.columns\n",
    "    for col_l in list_c:\n",
    "        print('-------------------------')\n",
    "        #print(col_l, temp[col_l].sort_values().unique())\n",
    "        print(col_l,'|кол-во строк',len(temp),'| кол-во NaN',temp[col_l].isna().sum(),\n",
    "        '| процент NaN', round(temp[col_l].isna().sum()/len(temp)*100, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86269b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во дубликатов: 0\n",
      "-------------------------\n",
      "Unnamed: 0 |кол-во строк 159292 | кол-во NaN 0 | процент NaN 0.0 %\n",
      "-------------------------\n",
      "text |кол-во строк 159292 | кол-во NaN 0 | процент NaN 0.0 %\n",
      "-------------------------\n",
      "toxic |кол-во строк 159292 | кол-во NaN 0 | процент NaN 0.0 %\n"
     ]
    }
   ],
   "source": [
    "check_data (data_toxic_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c48d53",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "- Данные изучены. Небольшой EDA не помешает, так как это аналитический проект. \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "-  проверку на сбалансированность \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет: \n",
    "\n",
    "    \n",
    "- describe(), info(), .sample() не помешали бы\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "- нет никакого промужуточного вывода в конце раздела, и никак он не выделен    \n",
    "\n",
    "\n",
    "\n",
    "- на несбалансированность обратил внимание, это хорошо, но у тебя во всем проекте нет ни одного графика, а ведь красивый, хорошо оформленный график может быть украшением проекта. Почему бы тут его не использовать?   \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3bc50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    print(tag)\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2853599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.4 s, sys: 124 ms, total: 33.5 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "   \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    text = text.lower()\n",
    "    text_re = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text_split=text_re.split()\n",
    "    lemm_text = [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in text_split]\n",
    "    return \" \".join(lemm_text)\n",
    "\n",
    "data_toxic_comments['lemm_text'] = data_toxic_comments['text'].apply(lemmatize_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a231cfb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "- WordNetLemmatizer  рабочий вариант, но у него есть особенности, для корректной работы ему нужно передавать не просто слово, но и POS-тег (Part of Speech, части речи). Набираемся ума-разума [тут](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/) ) \n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "    \n",
    "- после очистки и лемитизации можно провести частотный анализ текста/[облако слов](https://habr.com/ru/post/517410/) - чтобы получить общее представление о тематике и о наиболее часто встерчаемых словах Кроме того графики, рисунки делают проект визуально интересней\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe437d4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Комментарий студента:</b>\n",
    "не понимаю как применить POS.что я делаю не так?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80b232",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "У меня все сработало\n",
    "\n",
    "    \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cad9fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_toxic_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae6d68",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Да, всегда лучше проверить что получилось  в итоге, так всегда будет возможность поправить ошбку\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257fef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toxic_comments = data_toxic_comments.drop(['text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c66c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "target = data_toxic_comments['toxic']\n",
    "features = data_toxic_comments.drop(['toxic'], axis=1)\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=0.4, \n",
    "                                                                              random_state=1234567)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=0.5,\n",
    "                                                                            random_state=1234567)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['lemm_text'])\n",
    "features_valid = count_tf_idf.transform(features_valid['lemm_text'])\n",
    "features_test = count_tf_idf.transform(features_test['lemm_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750caa6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "train_test_split\n",
    "    \n",
    "    \n",
    "- random_state на месте\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "- Ниже ты используешь GridSearchCV, вопрос - зачем тебе валидационная выборка?   GS разобьет на выборки сам, а результат на валидационной можно посмотреть через .best_score_. Хорошо бы обьяснить зачем так делаешь\n",
    "\n",
    "\n",
    "\n",
    "- Обрати внимание на аргумент stratify, он позволит сохранить изначальное распределение таргетов во всех новых датасетах.  Существующий дисбаланс никуда не денется, но в каждом датасете он будет одинаковым.  Это важно потому что великий рандом может нам разбить датасеты так, что модель получит искаженное представление пропорциях единичек и нулей в таргете    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c7d52",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "values.astype('U')\n",
    "    \n",
    "    \n",
    "Да, в тренажере был текст на кирилице, там перевод в unicode оправдан. В нашем случае (латиница) это лишь  увеличит количество потребляемой памяти и это в лучшем случаи, в худшем он обрушает ядро.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba8eac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Комментарий студента:</b>\n",
    "убрал values.astype('U')\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf7124",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "👍\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea46f71",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Не забыли о стопсловах, они ни к чему и код побежит быстрей\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет:     \n",
    "\n",
    "Вопросик:\n",
    "\n",
    "А стопслова важней убирать  когда мы используем TF-IDF, или когда используе обычный CountVectorizer? \n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536adac5",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbaf635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры\n",
      "{'C': 10, 'random_state': 1234567, 'solver': 'newton-cg'}\n",
      "CPU times: user 4min 19s, sys: 8min 16s, total: 12min 35s\n",
      "Wall time: 12min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(random_state=1234567)\n",
    "hyperparams = [{'solver':['newton-cg', 'lbfgs', 'liblinear'],'C':[0.1, 1, 10],'random_state':[1234567]}]\n",
    "model_g = GridSearchCV(model, hyperparams, scoring='f1')\n",
    "model_g.fit(features_train, target_train)\n",
    "print(\"Лучшие параметры\")\n",
    "print(model_g.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28af73",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "    \n",
    "Не забываем random_state при инициализации модели, и тут и далее обрати внимание    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05956480",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "👍\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330d00a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "    \n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Молодец что используешь GrisSearch, но еще лучше использовать связку GridSearchCV + pipeline. \n",
    "\n",
    "\n",
    "О pipeline:\n",
    "\n",
    "[Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), это тема которая сразу затрагивает кроссвалидацию, тюнинг \"векторайз\", подбор гиперпараметров модели и о том что код стоит делать компактным.\n",
    "    \n",
    "    \n",
    "- в TfidfVectorizer(stop_words=stopwords) у тебя по умолчанию ngram_range=(1, 1), тут можно подбирать разное число n- грамм (и другие параметры), максимизируя метрику, но как объединить перебор по ngram_range с обучением моделей, чтобы не делать это по отдельности или с использованием цикла?! pipeline! Готовый [пример для работы с текстами](https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html)\n",
    "    \n",
    "    \n",
    "- как избежать ошибки подглядывания в будущее, когда мы предварительно работаем с данными (шкалирование, нормализация, TfidfVectorizer итп итд)? pipeline! особенно это важно, когда мы используем кроссвалидацию. Для TfidfVectorizer делаем .fit (обучаемся) на train, а transform на test, но точно также нужно сделать для валидационной выборки. Но GS делает валидационные внутри себя, спрашивается как добраться до нее и избежать подглядывания в будущее? Казалось бы никак, но нет! Pipeline! ) \n",
    "    \n",
    "    \n",
    "- pipeline позволяет делать наш код компактней и читабельней, это большой плюс, когда код будет раздуваться     \n",
    "    \n",
    "    \n",
    "\n",
    "         \n",
    "Если раньше не использовалА pipeline то могу посоветовать видео в котором [индус](https://www.youtube.com/watch?v=mOYJCR0IDk8&ab_channel=HimanshuChandra) на английском с сильным акцентом, но на пальцах обьясняет  самое непонятное (по моему опыту): сопряженность методов fit и transform. Там же есть и код и ссылка на текст. Мне помогло )\n",
    "\n",
    "\n",
    "\n",
    "В общем если сделать GS+pipeline будет вообще хорошо )  \n",
    "    \n",
    "<div>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9dd2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на валидации 0.7722087798133425\n",
      "CPU times: user 8.61 s, sys: 14 s, total: 22.6 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(random_state=1234567)\n",
    "model.set_params(**model_g.best_params_)\n",
    "model.fit(features_train, target_train)\n",
    "target_predict = model.predict(features_valid)\n",
    "f1_LR = f1_score(target_valid, target_predict)\n",
    "print('F1 на валидации', f1_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2b891",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "    \n",
    "Этот блок лишний.\n",
    "    \n",
    "- ты используешь GS как инструмент получить лучшие значения гиперпараметров, после чего вставляешь их в модель и опять обучаешь. Но GS уже это сделал, готовая моделька тут: .best_estimator_\n",
    "\n",
    "    \n",
    "- И валидационный датасет не нужен, потому что GS когда искал лучшие значения гиперпараметров, лучшее значение метрики на валидационном датасете (на самом деле нескольких, ведь кроссвалидация) сохранил в .best_score_    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b295e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат:\n",
      "{'max_depth': 45, 'random_state': 1234567}\n",
      "CPU times: user 8min 9s, sys: 15.2 s, total: 8min 24s\n",
      "Wall time: 8min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1234567)\n",
    "hyperparams = [{'max_depth':[x for x in range(10,50,5)], 'random_state':[1234567]}]\n",
    "model_grid = GridSearchCV(model, hyperparams, scoring='f1')\n",
    "model_grid.fit(features_train, target_train)\n",
    "print(\"Лучший результат:\")\n",
    "print(model_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5354b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на валидации 0.6960242467463006\n",
      "CPU times: user 16.8 s, sys: 327 ms, total: 17.2 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1234567)\n",
    "model.set_params(**model_grid.best_params_)\n",
    "model.fit(features_train, target_train)\n",
    "target_predict = model.predict(features_valid)\n",
    "f1_DTC = f1_score(target_valid, target_predict)\n",
    "print('F1 на валидации', f1_DTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ae97e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметры</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.772209</td>\n",
       "      <td>0.696024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Параметры  LogisticRegression  DecisionTreeClassifier\n",
       "0        F1            0.772209                0.696024"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezult = pd.DataFrame({ 'Параметры': ['F1'],\n",
    "                       'LogisticRegression':[f1_LR], 'DecisionTreeClassifier':[f1_DTC]})\n",
    "rezult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49210b59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "Наглядно и здорово что оформил в табличку   \n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17589bbe",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6948584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на валидации 0.7656652360515022\n",
      "CPU times: user 8.35 s, sys: 14.5 s, total: 22.8 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=1234567)\n",
    "model.set_params(**model_g.best_params_)\n",
    "model.fit(features_train, target_train)\n",
    "target_predict = model.predict(features_test)\n",
    "f1_LR = f1_score(target_test, target_predict)\n",
    "print('F1 на валидации', f1_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0357c",
   "metadata": {},
   "source": [
    "<b>Вывод:</b>  \n",
    "\n",
    "В данном проекте был рассмотрен способ нормализации текста, для дальнейшего использования в ML моделях.  \n",
    "\n",
    "При подготовке проекта был использован метод лемматизации и векторизации корпуса текста.  \n",
    "\n",
    "После было проведено обучение на двух классических моделях: LogisticRegression и DecisionTreeClassifier.  \n",
    "Модель LR показала наилучший результат по ключевой метрике и была взята в работу на тестовой выборке.\n",
    "На тестовой выборке по метрике F1 модель LogisticRegression() дала необходимый результат 0.77.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ab7e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "Кратенько добавил )\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9da22",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех: \n",
    "\n",
    "- Все верно, логика моделирования не нарушена, тут тестируем только лучшую модель отобранную на валидации, или парочку лучших, если на валидации результаты близки\n",
    "\n",
    "\n",
    "- Если студент получил на тесте f1 выше 0,75, это считается приемлемым результатом.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "Что может помочь добиться лучшего результата (от простого)? \n",
    "\n",
    "- использовать stratify. \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "- учесть дисбаланс класов в таргете. (но не oversampling, это скользкая дорожка, через class_weight)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "- полезно настраивать векторайзеры (тут пригодится pipeline)\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "- подобрать лучшие гиперпараметры с использованием кроссвалидации (тут пригодится GridSearchCV) Done!\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "- сгенерировать новые фичи, например  например посчитать число слов в тексте, длину слов итп итд. Или с помощью [тематического моделирования](https://pythobyte.com/python-for-nlp-topic-modeling-8fb3d689/) / использовать ембединги слов, учитывающие семантику, например [word2vec](https://radimrehurek.com/gensim/models/word2vec.html)) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "- попробовать другие модели. проект своеобразный выбор между вычислительными ограничениями (много примеров, расчеты могут затянуться) и задачей получить хорошую метрику (как это и бывает на практике), поэтому советовать \"тяжелые\", но мощные модели, чтобы у тебя все окончательно не повисло не буду (хотя есть вариант попробовать сделать на GPU).  А вот попробовать простые модели: SVC, NBC, логистическая регрессия, которые хорошо отработают с разряженными матрицами, могу. Простые модели - зато используем весь датасет. \n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c138b51",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "В конце проекта принято кратко описывать все проделанные шаги и полученные результаты. Зачем это нужно - когда проект захочет посмотреть будущий работодатель, у него может не быть времени на подробный разбор кода. Вероятнее всего он бегло просмотрит код, но захочет изучить результат, который будет в общем выводе. Поэтому все же советую написать общий вывод пообьемней: добавить пару слов о данных, работе с ними, о моделях, метриках\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9a47b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Комментарий студента:</b>\n",
    "Добавлен вывод \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637cecc8",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Сергей, у тебя старательно выполненная работа, все четко, осмысленно. \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Замечания на будущее:\n",
    "    \n",
    "- Комментарии к коду отсутствуют - коллеги могут не понять хода твоих мыслей. \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "Я оставил небольшие советы и вопросики (если есть время и желание можешь воспользоваться/ответить).\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer используем с POS - тег \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- .astype('U') лишнее, стоит экономить ресурсы, иначе может даже ядро обрушиться\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- не забываем о random_state\n",
    "\n",
    "\n",
    "\n",
    "- общий вывод - лицо проекта стоит сделать пообьемней   \n",
    "\n",
    "\n",
    "    \n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc54e44",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "    \n",
    "Глеб у меня лемматизация запустилась (в первый раз что то выскочила, потом все запустилось), сейчас трудно уже сказать что было не так. Если опять появится шли обратно, разберемся.\n",
    "\n",
    "    \n",
    "    \n",
    "Что осталось из красного:\n",
    "\n",
    "    \n",
    "-  не забываем о random_state при инициализации модели\n",
    "\n",
    "    \n",
    "    \n",
    "На связи    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09937bc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Комментарий студента:</b>\n",
    " добавил random_state\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d36e9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Комментарий студента:</b>\n",
    " Марат, большое спасибо за советы и комментарии. Я вижу и обязательно к ним вернусь. просто сейчас плохо со временим из-за переезда  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3126397",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Глеб, тобой исправлено красное, желтое не тронуто - твое право ) Тем не менее надеюсь мои советы и вопросики будут полезны и ты узнаеешь что то новое.\n",
    "Отличная работа. Желаю успехов в дальнейшей учебе!\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccdf6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2201,
    "start_time": "2022-10-04T10:33:15.993Z"
   },
   {
    "duration": 2416,
    "start_time": "2022-10-04T10:33:18.197Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-04T10:33:20.615Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-04T10:33:20.629Z"
   },
   {
    "duration": 299,
    "start_time": "2022-10-04T10:33:20.636Z"
   },
   {
    "duration": 34893,
    "start_time": "2022-10-04T10:33:20.937Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-04T10:33:55.831Z"
   },
   {
    "duration": 40,
    "start_time": "2022-10-04T10:33:55.843Z"
   },
   {
    "duration": 10985,
    "start_time": "2022-10-04T10:33:55.885Z"
   },
   {
    "duration": 826914,
    "start_time": "2022-10-04T10:34:06.872Z"
   },
   {
    "duration": 26221,
    "start_time": "2022-10-04T10:47:53.788Z"
   },
   {
    "duration": 562971,
    "start_time": "2022-10-04T10:48:20.011Z"
   },
   {
    "duration": 17566,
    "start_time": "2022-10-04T10:57:42.983Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-04T10:58:00.553Z"
   },
   {
    "duration": 25438,
    "start_time": "2022-10-04T10:58:00.564Z"
   },
   {
    "duration": 99,
    "start_time": "2022-10-04T18:03:00.165Z"
   },
   {
    "duration": 1666,
    "start_time": "2022-10-04T18:03:07.197Z"
   },
   {
    "duration": 2487,
    "start_time": "2022-10-04T18:03:08.864Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-04T18:03:11.353Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-04T18:03:11.366Z"
   },
   {
    "duration": 272,
    "start_time": "2022-10-04T18:03:11.371Z"
   },
   {
    "duration": 35256,
    "start_time": "2022-10-04T18:03:11.645Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-04T18:03:46.903Z"
   },
   {
    "duration": 21,
    "start_time": "2022-10-04T18:03:46.916Z"
   },
   {
    "duration": 6047,
    "start_time": "2022-10-04T18:03:46.939Z"
   },
   {
    "duration": 687454,
    "start_time": "2022-10-04T18:03:52.988Z"
   },
   {
    "duration": 20310,
    "start_time": "2022-10-04T18:15:20.443Z"
   },
   {
    "duration": 524445,
    "start_time": "2022-10-04T18:15:40.754Z"
   },
   {
    "duration": 16854,
    "start_time": "2022-10-04T18:24:25.200Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-04T18:24:42.055Z"
   },
   {
    "duration": 19882,
    "start_time": "2022-10-04T18:24:42.065Z"
   },
   {
    "duration": 1760,
    "start_time": "2022-10-05T05:52:49.894Z"
   },
   {
    "duration": 3300,
    "start_time": "2022-10-05T05:52:51.656Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-05T05:52:54.957Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T05:52:54.972Z"
   },
   {
    "duration": 300,
    "start_time": "2022-10-05T05:52:54.978Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T05:52:55.280Z"
   },
   {
    "duration": 710,
    "start_time": "2022-10-05T05:52:55.295Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-05T05:52:56.008Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T05:52:56.025Z"
   },
   {
    "duration": 1439,
    "start_time": "2022-10-05T05:52:56.031Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T05:52:57.471Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T05:52:57.473Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T05:52:57.474Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T05:52:57.476Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T05:52:57.477Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T05:52:57.477Z"
   },
   {
    "duration": 1353,
    "start_time": "2022-10-05T05:59:15.453Z"
   },
   {
    "duration": 1391,
    "start_time": "2022-10-05T06:01:05.157Z"
   },
   {
    "duration": 898,
    "start_time": "2022-10-05T06:01:06.550Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-05T06:01:07.450Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T06:01:07.463Z"
   },
   {
    "duration": 298,
    "start_time": "2022-10-05T06:01:07.469Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T06:01:07.769Z"
   },
   {
    "duration": 695,
    "start_time": "2022-10-05T06:01:07.774Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-05T06:01:08.470Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-05T06:01:08.480Z"
   },
   {
    "duration": 1271,
    "start_time": "2022-10-05T06:01:08.488Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T06:01:09.761Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T06:01:09.762Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T06:01:09.764Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T06:01:09.765Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T06:01:09.767Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T06:01:09.768Z"
   },
   {
    "duration": 1508,
    "start_time": "2022-10-05T06:05:34.372Z"
   },
   {
    "duration": 822,
    "start_time": "2022-10-05T06:05:35.882Z"
   },
   {
    "duration": 16,
    "start_time": "2022-10-05T06:05:36.706Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-05T06:05:36.724Z"
   },
   {
    "duration": 293,
    "start_time": "2022-10-05T06:05:36.731Z"
   },
   {
    "duration": 32716,
    "start_time": "2022-10-05T06:05:37.026Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-05T06:06:09.744Z"
   },
   {
    "duration": 51,
    "start_time": "2022-10-05T06:06:09.755Z"
   },
   {
    "duration": 6095,
    "start_time": "2022-10-05T06:06:09.808Z"
   },
   {
    "duration": 735532,
    "start_time": "2022-10-05T06:06:15.905Z"
   },
   {
    "duration": 22400,
    "start_time": "2022-10-05T06:18:31.439Z"
   },
   {
    "duration": 489455,
    "start_time": "2022-10-05T06:18:53.840Z"
   },
   {
    "duration": 16619,
    "start_time": "2022-10-05T06:27:03.297Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-05T06:27:19.919Z"
   },
   {
    "duration": 22191,
    "start_time": "2022-10-05T06:27:19.929Z"
   },
   {
    "duration": 102,
    "start_time": "2022-10-05T06:36:01.138Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T06:42:42.421Z"
   },
   {
    "duration": 1311,
    "start_time": "2022-10-05T06:42:45.491Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-05T07:18:33.628Z"
   },
   {
    "duration": 1370,
    "start_time": "2022-10-05T07:18:43.196Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T07:20:30.433Z"
   },
   {
    "duration": 2922,
    "start_time": "2022-10-05T07:20:32.384Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T07:23:45.865Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-05T07:23:48.117Z"
   },
   {
    "duration": 22,
    "start_time": "2022-10-05T07:24:02.802Z"
   },
   {
    "duration": 19,
    "start_time": "2022-10-05T07:24:38.107Z"
   },
   {
    "duration": 18,
    "start_time": "2022-10-05T07:24:46.223Z"
   },
   {
    "duration": 83,
    "start_time": "2022-10-05T07:25:24.917Z"
   },
   {
    "duration": 149,
    "start_time": "2022-10-05T07:34:51.921Z"
   },
   {
    "duration": 1932,
    "start_time": "2022-10-05T11:10:35.280Z"
   },
   {
    "duration": 2417,
    "start_time": "2022-10-05T11:10:37.214Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-05T11:10:39.632Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-05T11:10:39.647Z"
   },
   {
    "duration": 267,
    "start_time": "2022-10-05T11:10:39.660Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:10:39.929Z"
   },
   {
    "duration": 645,
    "start_time": "2022-10-05T11:10:39.934Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-05T11:10:40.580Z"
   },
   {
    "duration": 17,
    "start_time": "2022-10-05T11:10:40.590Z"
   },
   {
    "duration": 1726,
    "start_time": "2022-10-05T11:10:40.608Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:10:42.335Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:10:42.337Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:10:42.338Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:10:42.339Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:10:42.340Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:10:42.340Z"
   },
   {
    "duration": 19,
    "start_time": "2022-10-05T11:19:16.329Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-05T11:19:46.243Z"
   },
   {
    "duration": 23,
    "start_time": "2022-10-05T11:19:56.348Z"
   },
   {
    "duration": 1642,
    "start_time": "2022-10-05T11:20:17.663Z"
   },
   {
    "duration": 25,
    "start_time": "2022-10-05T11:21:03.404Z"
   },
   {
    "duration": 18,
    "start_time": "2022-10-05T11:21:08.573Z"
   },
   {
    "duration": 19,
    "start_time": "2022-10-05T11:21:17.510Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-05T11:21:35.817Z"
   },
   {
    "duration": 24,
    "start_time": "2022-10-05T11:22:09.956Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-05T11:22:18.318Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-05T11:24:00.147Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-05T11:24:12.459Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-05T11:24:30.005Z"
   },
   {
    "duration": 162,
    "start_time": "2022-10-05T11:24:58.779Z"
   },
   {
    "duration": 93,
    "start_time": "2022-10-05T11:25:19.499Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:25:26.868Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:25:33.051Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:25:38.341Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-05T11:25:45.422Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-05T11:25:58.079Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-05T11:27:52.893Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:28:00.421Z"
   },
   {
    "duration": 19,
    "start_time": "2022-10-05T11:28:18.472Z"
   },
   {
    "duration": 1657,
    "start_time": "2022-10-05T11:28:40.619Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-05T11:28:53.652Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-05T11:29:12.966Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-05T11:29:20.400Z"
   },
   {
    "duration": 715,
    "start_time": "2022-10-05T11:29:33.017Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-05T11:29:45.207Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-05T11:29:50.219Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:29:50.690Z"
   },
   {
    "duration": 267,
    "start_time": "2022-10-05T11:29:51.819Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-05T11:29:57.604Z"
   },
   {
    "duration": 24840,
    "start_time": "2022-10-05T11:30:20.616Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T11:30:52.620Z"
   },
   {
    "duration": 10973,
    "start_time": "2022-10-05T11:30:55.066Z"
   },
   {
    "duration": 38542,
    "start_time": "2022-10-05T11:31:40.105Z"
   },
   {
    "duration": 2074,
    "start_time": "2022-10-05T11:32:40.265Z"
   },
   {
    "duration": 835,
    "start_time": "2022-10-05T11:32:42.341Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-05T11:32:43.178Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:32:43.200Z"
   },
   {
    "duration": 300,
    "start_time": "2022-10-05T11:32:43.207Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:32:43.509Z"
   },
   {
    "duration": 1840,
    "start_time": "2022-10-05T11:35:29.058Z"
   },
   {
    "duration": 769,
    "start_time": "2022-10-05T11:35:30.901Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-05T11:35:31.672Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-05T11:35:31.688Z"
   },
   {
    "duration": 265,
    "start_time": "2022-10-05T11:35:31.704Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T11:35:31.972Z"
   },
   {
    "duration": 341358,
    "start_time": "2022-10-05T11:35:31.977Z"
   },
   {
    "duration": 2,
    "start_time": "2022-10-05T11:41:13.337Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-05T11:41:13.341Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T11:41:13.354Z"
   },
   {
    "duration": 886,
    "start_time": "2022-10-05T11:41:13.359Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:41:14.246Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:41:14.247Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:41:14.248Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:41:14.249Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:41:14.250Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T11:41:14.251Z"
   },
   {
    "duration": 1732,
    "start_time": "2022-10-05T12:41:41.807Z"
   },
   {
    "duration": 3533,
    "start_time": "2022-10-05T12:41:43.541Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-05T12:41:47.075Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T12:41:47.090Z"
   },
   {
    "duration": 275,
    "start_time": "2022-10-05T12:41:47.095Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T12:41:47.373Z"
   },
   {
    "duration": 841,
    "start_time": "2022-10-05T12:41:47.378Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-05T12:41:48.221Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-05T12:41:48.231Z"
   },
   {
    "duration": 2954,
    "start_time": "2022-10-05T12:41:48.238Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T12:41:51.193Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T12:41:51.195Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T12:41:51.196Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T12:41:51.197Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T12:41:51.198Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T12:41:51.199Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T12:46:14.962Z"
   },
   {
    "duration": 1465,
    "start_time": "2022-10-05T12:46:19.406Z"
   },
   {
    "duration": 1597,
    "start_time": "2022-10-05T13:14:21.235Z"
   },
   {
    "duration": 853,
    "start_time": "2022-10-05T13:14:22.834Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-05T13:14:23.689Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T13:14:23.706Z"
   },
   {
    "duration": 314,
    "start_time": "2022-10-05T13:14:23.711Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-05T13:14:24.027Z"
   },
   {
    "duration": 956,
    "start_time": "2022-10-05T13:14:24.033Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-05T13:14:24.991Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-05T13:14:25.002Z"
   },
   {
    "duration": 2053,
    "start_time": "2022-10-05T13:14:25.009Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T13:14:27.064Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T13:14:27.065Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T13:14:27.066Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T13:14:27.067Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T13:14:27.068Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-05T13:14:27.069Z"
   },
   {
    "duration": 1567,
    "start_time": "2022-10-05T13:16:35.936Z"
   },
   {
    "duration": 858,
    "start_time": "2022-10-05T13:16:37.505Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-05T13:16:38.364Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T13:16:38.379Z"
   },
   {
    "duration": 282,
    "start_time": "2022-10-05T13:16:38.396Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-05T13:16:38.680Z"
   },
   {
    "duration": 33561,
    "start_time": "2022-10-05T13:16:38.685Z"
   },
   {
    "duration": 10,
    "start_time": "2022-10-05T13:17:12.247Z"
   },
   {
    "duration": 44,
    "start_time": "2022-10-05T13:17:12.258Z"
   },
   {
    "duration": 6417,
    "start_time": "2022-10-05T13:17:12.304Z"
   },
   {
    "duration": 756423,
    "start_time": "2022-10-05T13:17:18.722Z"
   },
   {
    "duration": 22671,
    "start_time": "2022-10-05T13:29:55.147Z"
   },
   {
    "duration": 505280,
    "start_time": "2022-10-05T13:30:17.820Z"
   },
   {
    "duration": 17184,
    "start_time": "2022-10-05T13:38:43.102Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-05T13:39:00.288Z"
   },
   {
    "duration": 22839,
    "start_time": "2022-10-05T13:39:00.301Z"
   },
   {
    "duration": 77,
    "start_time": "2022-10-05T13:39:23.141Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
